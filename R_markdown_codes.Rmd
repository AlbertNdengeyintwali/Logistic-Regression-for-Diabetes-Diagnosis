---
title: "R codes for Logistic Regression for Diabetes Diagnosis"
author: "Albert Ndengeyintwali"
date: "2023-10-24"
output:
  word_document: default
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

 

## Load necessary libraries


```{r load_libraries, message=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)
library(dplyr)
library(magrittr)
library(caret)
library(pROC)
library(ROCR)
library(robustbase)
```




## Read the dataset


```{r}

diabetes <- read.csv("diabetes.csv") 

```


## Crating histogram for each Explanatory variables to see how they are distributed

```{r}
# Loop through all columns except 'Outcome'
for (col in colnames(diabetes)[colnames(diabetes) != "Outcome"]) {
  # Create histogram for each column
  hist(diabetes[[col]], main = paste("Histogram of", col), xlab = col, col = "lightblue", border = "black")
}


```


## Crating Boxplot for each Explanatory variables to see if there are outliers


```{r}
# Loop through all columns except 'Outcome'
for (col in colnames(diabetes)[colnames(diabetes) != "Outcome"]) {
  # Create histogram for each column
  boxplot(diabetes[[col]], main = paste("Histogram of", col), xlab = col, col = "lightblue", border = "black")
}

```

## Split the data into 70% training and 30% testing


```{r}
set.seed(123)  # For reproducibility
data_split <- createDataPartition(y = diabetes$Outcome, p = 0.7, list = FALSE)   

# Create the training set
train_data <- diabetes[data_split, ]

# Create the testing set
test_data <- diabetes[-data_split, ]


```


## Train a robust logistic regression model on training data

```{r}
# Fit a robust logistic regression model using "BY" method
robust_log_model <- glmrob(Outcome ~ ., data = train_data, family = binomial, method = "BY")
summary(robust_log_model)



```


### Make predictions again


```{r}
log_odds <- predict(robust_log_model, test_data, type = "link")
predicted_prob <- 1 / (1 + exp(-log_odds))
# Convert predictions to binary outcomes (e.g., threshold = 0.5)
predictions_binary <- ifelse(predicted_prob > 0.5, 1, 0)

```


## Confusion Matrix

```{r}

confusionMatrix(factor(predictions_binary), factor(test_data$Outcome))

```

## Accuracy,Precision, Recall, F1 Score

```{r}

accuracy <- mean(predictions_binary == test_data$Outcome)
precision <- posPredValue(factor(predictions_binary), factor(test_data$Outcome))
recall <- sensitivity(factor(predictions_binary), factor(test_data$Outcome))
f1 <- (2 * precision * recall) / (precision + recall)
cat("Accuracy: ", accuracy, "\n",
    "Precision: ", precision, "\n",
    "Recall: ", recall, "\n",
    "F1-Score: ", f1, "\n")


```

# Generate ROC curve using pROC and ROCR

```{r pressure, echo=FALSE}

# Generate ROC curve using pROC
roc_curve <- roc(test_data$Outcome, predicted_prob)

# Create the prediction object for ROCR
actual <- test_data$Outcome 
pred <- prediction(predicted_prob, actual)

# Calculate performance for ROCR (True Positive Rate and False Positive Rate)
perf <- performance(pred, "tpr", "fpr")

# Set up the layout for a single image with two plots
par(mfrow = c(1, 2))  


plot(roc_curve, main = "ROC Curve from pROC", col = "blue", lwd = 2)
auc_value_pROC <- auc(roc_curve)
text(0.6, 0.3, paste("AUC =", round(auc_value_pROC, 4)), col = "red", cex = 1.2)

# Plot the second ROC curve (from ROCR) in dark green
plot(perf, col = "darkgreen", lwd = 2, main = "ROC Curve from ROCR", xlim = c(0, 1), ylim = c(0, 1))
auc_value_ROCR <- performance(pred, measure = "auc")@y.values[[1]]
text(0.6, 0.3, paste("AUC =", round(auc_value_ROCR, 4)), col = "purple", cex = 1.2)
# Add diagonal reference line for ROCR
abline(a = 0, b = 1, col = "red", lty = 2)



```

## Predicted Probability of Diabetes


```{r}
# Coefficients from the logistic regression model 
intercept <- -8.515855
beta_pregnancies <- 0.104525
beta_glucose <- 0.036182
beta_blood_pressure <- -0.012803
beta_skin_thickness <- 0.003630
beta_insulin <- -0.001745
beta_bmi <- 0.089775
beta_diabetes_pedigree_function <- 0.707081
beta_age <- 0.017299

# Input values of an individual with the first observation
Pregnancies <- 6
Glucose <- 148
BloodPressure <- 72
SkinThickness <- 35
Insulin <- 0
BMI <- 33.6
DiabetesPedigreeFunction <- 0.627
Age <- 50


# Calculate the logit (linear predictor)
logit <- intercept + 
  (beta_pregnancies * Pregnancies) + 
  (beta_glucose * Glucose) + 
  (beta_blood_pressure * BloodPressure) + 
  (beta_skin_thickness * SkinThickness) + 
  (beta_insulin * Insulin) + 
  (beta_bmi * BMI) + 
  (beta_diabetes_pedigree_function * DiabetesPedigreeFunction) + 
  (beta_age * Age)

# Calculate the probability using the logistic function
probability <- exp(logit) / (1 + exp(logit))

cat("The predicted probability of having diabetes is:", probability)

```








